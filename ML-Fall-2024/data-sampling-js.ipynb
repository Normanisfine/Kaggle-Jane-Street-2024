{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-30T16:58:42.136198Z","iopub.execute_input":"2024-11-30T16:58:42.136708Z","iopub.status.idle":"2024-11-30T16:58:42.156547Z","shell.execute_reply.started":"2024-11-30T16:58:42.136670Z","shell.execute_reply":"2024-11-30T16:58:42.155392Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/jane-street-real-time-market-data-forecasting/responders.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/sample_submission.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/features.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=4/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=5/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=6/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=3/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=1/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=8/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=2/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=7/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=9/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet/date_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/jane_street_gateway.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/jane_street_inference_server.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/__init__.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/templates.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/relay.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/__init__.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/__init__.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# configs\npd.set_option('display.max_columns', None) # we want to display all columns in this notebook\npd.set_option('display.max_rows', 100) # increase number of displayed rows","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:58:46.875975Z","iopub.execute_input":"2024-11-30T16:58:46.876324Z","iopub.status.idle":"2024-11-30T16:58:46.881889Z","shell.execute_reply.started":"2024-11-30T16:58:46.876294Z","shell.execute_reply":"2024-11-30T16:58:46.880569Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"input_path = '/kaggle/input/jane-street-real-time-market-data-forecasting'","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:58:48.869039Z","iopub.execute_input":"2024-11-30T16:58:48.869382Z","iopub.status.idle":"2024-11-30T16:58:48.874795Z","shell.execute_reply.started":"2024-11-30T16:58:48.869351Z","shell.execute_reply":"2024-11-30T16:58:48.873350Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"%%time\n# Define the base path for the dataset\nbase_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/'\n\n# Can't concat all partitions together, as it would kill the kernel\ntrain_file_0 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet\")\ntrain_file_1 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=1/part-0.parquet\")\ntrain_file_2 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=2/part-0.parquet\")\ntrain_file_3 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=3/part-0.parquet\")\ntrain_file_4 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=4/part-0.parquet\")\ntrain_file_5 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=5/part-0.parquet\")\ntrain_file_6 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=6/part-0.parquet\")\ntrain_file_7 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=7/part-0.parquet\")\ntrain_file_8 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=8/part-0.parquet\")\ntrain_file_9 = pd.read_parquet(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=9/part-0.parquet\")","metadata":{"execution":{"iopub.status.busy":"2024-11-30T16:58:50.318983Z","iopub.execute_input":"2024-11-30T16:58:50.319368Z","iopub.status.idle":"2024-11-30T17:00:32.460715Z","shell.execute_reply.started":"2024-11-30T16:58:50.319334Z","shell.execute_reply":"2024-11-30T17:00:32.458770Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 1min 11s, sys: 1min 32s, total: 2min 43s\nWall time: 1min 42s\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_file_0.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-30T17:02:01.053064Z","iopub.execute_input":"2024-11-30T17:02:01.053640Z","iopub.status.idle":"2024-11-30T17:02:01.135828Z","shell.execute_reply.started":"2024-11-30T17:02:01.053577Z","shell.execute_reply":"2024-11-30T17:02:01.134741Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   date_id  time_id  symbol_id    weight  feature_00  feature_01  feature_02  \\\n0        0        0          1  3.889038         NaN         NaN         NaN   \n1        0        0          7  1.370613         NaN         NaN         NaN   \n2        0        0          9  2.285698         NaN         NaN         NaN   \n3        0        0         10  0.690606         NaN         NaN         NaN   \n4        0        0         14  0.440570         NaN         NaN         NaN   \n\n   feature_03  feature_04  feature_05  feature_06  feature_07  feature_08  \\\n0         NaN         NaN    0.851033    0.242971    0.263400   -0.891687   \n1         NaN         NaN    0.676961    0.151984    0.192465   -0.521729   \n2         NaN         NaN    1.056285    0.187227    0.249901   -0.773050   \n3         NaN         NaN    1.139366    0.273328    0.306549   -1.262223   \n4         NaN         NaN    0.955200    0.262404    0.344457   -0.613813   \n\n   feature_09  feature_10  feature_11  feature_12  feature_13  feature_14  \\\n0          11           7          76   -0.883028    0.003067   -0.744703   \n1          11           7          76   -0.865307   -0.225629   -0.582163   \n2          11           7          76   -0.675719   -0.199404   -0.586798   \n3          42           5         150   -0.694008    3.004091    0.114809   \n4          44           3          16   -0.947351   -0.030018   -0.502379   \n\n   feature_15  feature_16  feature_17  feature_18  feature_19  feature_20  \\\n0         NaN   -0.169586         NaN   -1.335938   -1.707803    0.910130   \n1         NaN    0.317467         NaN   -1.250016   -1.682929    1.412757   \n2         NaN   -0.814909         NaN   -1.296782   -2.040234    0.639589   \n3         NaN   -0.251882         NaN   -1.902009   -0.979447    0.241165   \n4         NaN    0.646086         NaN   -1.844685   -1.586560   -0.182024   \n\n   feature_21  feature_22  feature_23  feature_24  feature_25  feature_26  \\\n0         NaN    1.636431    1.522133   -1.551398   -0.229627         NaN   \n1         NaN    0.520378    0.744132   -0.788658    0.641776         NaN   \n2         NaN    1.597359    0.657514   -1.350148    0.364215         NaN   \n3         NaN   -0.392359   -0.224699   -2.129397   -0.855287         NaN   \n4         NaN   -0.969949   -0.673813   -1.282132   -1.399894         NaN   \n\n   feature_27  feature_28  feature_29  feature_30  feature_31  feature_32  \\\n0         NaN    1.378301   -0.283712    0.123196         NaN         NaN   \n1         NaN    0.227200    0.580907    1.128879         NaN         NaN   \n2         NaN   -0.017751   -0.317361   -0.122379         NaN         NaN   \n3         NaN    0.404142   -0.578156    0.105702         NaN         NaN   \n4         NaN    0.043815   -0.320225   -0.031713         NaN         NaN   \n\n   feature_33  feature_34  feature_35  feature_36  feature_37  feature_38  \\\n0         NaN    0.281180    0.269163    0.349028   -0.012596   -0.225932   \n1         NaN   -1.512286   -1.414357   -1.823322   -0.082763   -0.184119   \n2         NaN   -0.320921   -0.958090   -2.436589    0.070999   -0.245239   \n3         NaN    0.544138   -0.087091   -1.500147   -0.201288   -0.038042   \n4         NaN   -0.088420   -0.995003   -2.635336   -0.196461   -0.618719   \n\n   feature_39  feature_40  feature_41  feature_42  feature_43  feature_44  \\\n0         NaN   -1.073602         NaN         NaN   -0.181716         NaN   \n1         NaN         NaN         NaN         NaN         NaN         NaN   \n2         NaN         NaN         NaN         NaN         NaN         NaN   \n3         NaN         NaN         NaN         NaN         NaN         NaN   \n4         NaN         NaN         NaN         NaN         NaN         NaN   \n\n   feature_45  feature_46  feature_47  feature_48  feature_49  feature_50  \\\n0         NaN         NaN    0.564021    2.088506    0.832022         NaN   \n1         NaN         NaN  -10.835207   -0.002704   -0.621836         NaN   \n2         NaN         NaN   -1.420632   -3.515137   -4.677760         NaN   \n3         NaN         NaN    0.382074    2.669135    0.611711         NaN   \n4         NaN         NaN   -2.014600   -2.321076   -3.711265         NaN   \n\n   feature_51  feature_52  feature_53  feature_54  feature_55  feature_56  \\\n0    0.204797         NaN         NaN   -0.808103         NaN   -2.037683   \n1    1.172836         NaN         NaN   -1.625862         NaN   -1.410017   \n2    0.535897         NaN         NaN   -0.725420         NaN   -2.294170   \n3    2.413415         NaN         NaN    1.313203         NaN   -0.810125   \n4    1.253902         NaN         NaN    0.476195         NaN   -0.771732   \n\n   feature_57  feature_58  feature_59  feature_60  feature_61  feature_62  \\\n0    0.727661         NaN   -0.989118   -0.345213    -1.36224         NaN   \n1    1.063013         NaN    0.888355    0.467994    -1.36224         NaN   \n2    1.764551         NaN   -0.120789   -0.063458    -1.36224         NaN   \n3    2.939022         NaN    3.988801    1.834661    -1.36224         NaN   \n4    2.843421         NaN    1.379815    0.411827    -1.36224         NaN   \n\n   feature_63  feature_64  feature_65  feature_66  feature_67  feature_68  \\\n0         NaN         NaN         NaN         NaN   -1.251104   -0.110252   \n1         NaN         NaN         NaN         NaN   -1.065759    0.013322   \n2         NaN         NaN         NaN         NaN   -0.882604   -0.072482   \n3         NaN         NaN         NaN         NaN   -0.697595    1.074309   \n4         NaN         NaN         NaN         NaN   -0.948601   -0.136814   \n\n   feature_69  feature_70  feature_71  feature_72  feature_73  feature_74  \\\n0   -0.491157   -1.022690    0.152241   -0.659864         NaN         NaN   \n1   -0.592855   -1.052685   -0.393726   -0.741603         NaN         NaN   \n2   -0.617934   -0.863230   -0.241892   -0.709919         NaN         NaN   \n3   -0.206929   -0.530602    4.765215    0.571554         NaN         NaN   \n4   -0.447704   -1.141761    0.099631   -0.661928         NaN         NaN   \n\n   feature_75  feature_76  feature_77  feature_78  responder_0  responder_1  \\\n0   -0.261412   -0.211486   -0.335556   -0.281498     0.738489    -0.069556   \n1   -0.281207   -0.182894   -0.245565   -0.302441     2.965889     1.190077   \n2    0.377131    0.300724   -0.106842   -0.096792    -0.864488    -0.280303   \n3   -0.226891   -0.251412   -0.215522   -0.296244     0.408499     0.223992   \n4    3.678076    2.793581    2.618250    3.418133    -0.373387    -0.502764   \n\n   responder_2  responder_3  responder_4  responder_5  responder_6  \\\n0     1.380875     2.005353     0.186018     1.218368     0.775981   \n1    -0.523998     3.849921     2.626981     5.000000     0.703665   \n2    -0.326697     0.375781     1.271291     0.099793     2.109352   \n3     2.294888     1.097444     1.225872     1.225376     1.114137   \n4    -0.348021    -3.928148    -1.591366    -5.000000    -3.572820   \n\n   responder_7  responder_8  \n0     0.346999     0.095504  \n1     0.216683     0.778639  \n2     0.670881     0.772828  \n3     0.775199    -1.379516  \n4    -1.089123    -5.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>time_id</th>\n      <th>symbol_id</th>\n      <th>weight</th>\n      <th>feature_00</th>\n      <th>feature_01</th>\n      <th>feature_02</th>\n      <th>feature_03</th>\n      <th>feature_04</th>\n      <th>feature_05</th>\n      <th>feature_06</th>\n      <th>feature_07</th>\n      <th>feature_08</th>\n      <th>feature_09</th>\n      <th>feature_10</th>\n      <th>feature_11</th>\n      <th>feature_12</th>\n      <th>feature_13</th>\n      <th>feature_14</th>\n      <th>feature_15</th>\n      <th>feature_16</th>\n      <th>feature_17</th>\n      <th>feature_18</th>\n      <th>feature_19</th>\n      <th>feature_20</th>\n      <th>feature_21</th>\n      <th>feature_22</th>\n      <th>feature_23</th>\n      <th>feature_24</th>\n      <th>feature_25</th>\n      <th>feature_26</th>\n      <th>feature_27</th>\n      <th>feature_28</th>\n      <th>feature_29</th>\n      <th>feature_30</th>\n      <th>feature_31</th>\n      <th>feature_32</th>\n      <th>feature_33</th>\n      <th>feature_34</th>\n      <th>feature_35</th>\n      <th>feature_36</th>\n      <th>feature_37</th>\n      <th>feature_38</th>\n      <th>feature_39</th>\n      <th>feature_40</th>\n      <th>feature_41</th>\n      <th>feature_42</th>\n      <th>feature_43</th>\n      <th>feature_44</th>\n      <th>feature_45</th>\n      <th>feature_46</th>\n      <th>feature_47</th>\n      <th>feature_48</th>\n      <th>feature_49</th>\n      <th>feature_50</th>\n      <th>feature_51</th>\n      <th>feature_52</th>\n      <th>feature_53</th>\n      <th>feature_54</th>\n      <th>feature_55</th>\n      <th>feature_56</th>\n      <th>feature_57</th>\n      <th>feature_58</th>\n      <th>feature_59</th>\n      <th>feature_60</th>\n      <th>feature_61</th>\n      <th>feature_62</th>\n      <th>feature_63</th>\n      <th>feature_64</th>\n      <th>feature_65</th>\n      <th>feature_66</th>\n      <th>feature_67</th>\n      <th>feature_68</th>\n      <th>feature_69</th>\n      <th>feature_70</th>\n      <th>feature_71</th>\n      <th>feature_72</th>\n      <th>feature_73</th>\n      <th>feature_74</th>\n      <th>feature_75</th>\n      <th>feature_76</th>\n      <th>feature_77</th>\n      <th>feature_78</th>\n      <th>responder_0</th>\n      <th>responder_1</th>\n      <th>responder_2</th>\n      <th>responder_3</th>\n      <th>responder_4</th>\n      <th>responder_5</th>\n      <th>responder_6</th>\n      <th>responder_7</th>\n      <th>responder_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.889038</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.851033</td>\n      <td>0.242971</td>\n      <td>0.263400</td>\n      <td>-0.891687</td>\n      <td>11</td>\n      <td>7</td>\n      <td>76</td>\n      <td>-0.883028</td>\n      <td>0.003067</td>\n      <td>-0.744703</td>\n      <td>NaN</td>\n      <td>-0.169586</td>\n      <td>NaN</td>\n      <td>-1.335938</td>\n      <td>-1.707803</td>\n      <td>0.910130</td>\n      <td>NaN</td>\n      <td>1.636431</td>\n      <td>1.522133</td>\n      <td>-1.551398</td>\n      <td>-0.229627</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.378301</td>\n      <td>-0.283712</td>\n      <td>0.123196</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.281180</td>\n      <td>0.269163</td>\n      <td>0.349028</td>\n      <td>-0.012596</td>\n      <td>-0.225932</td>\n      <td>NaN</td>\n      <td>-1.073602</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.181716</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.564021</td>\n      <td>2.088506</td>\n      <td>0.832022</td>\n      <td>NaN</td>\n      <td>0.204797</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.808103</td>\n      <td>NaN</td>\n      <td>-2.037683</td>\n      <td>0.727661</td>\n      <td>NaN</td>\n      <td>-0.989118</td>\n      <td>-0.345213</td>\n      <td>-1.36224</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.251104</td>\n      <td>-0.110252</td>\n      <td>-0.491157</td>\n      <td>-1.022690</td>\n      <td>0.152241</td>\n      <td>-0.659864</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.261412</td>\n      <td>-0.211486</td>\n      <td>-0.335556</td>\n      <td>-0.281498</td>\n      <td>0.738489</td>\n      <td>-0.069556</td>\n      <td>1.380875</td>\n      <td>2.005353</td>\n      <td>0.186018</td>\n      <td>1.218368</td>\n      <td>0.775981</td>\n      <td>0.346999</td>\n      <td>0.095504</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1.370613</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.676961</td>\n      <td>0.151984</td>\n      <td>0.192465</td>\n      <td>-0.521729</td>\n      <td>11</td>\n      <td>7</td>\n      <td>76</td>\n      <td>-0.865307</td>\n      <td>-0.225629</td>\n      <td>-0.582163</td>\n      <td>NaN</td>\n      <td>0.317467</td>\n      <td>NaN</td>\n      <td>-1.250016</td>\n      <td>-1.682929</td>\n      <td>1.412757</td>\n      <td>NaN</td>\n      <td>0.520378</td>\n      <td>0.744132</td>\n      <td>-0.788658</td>\n      <td>0.641776</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.227200</td>\n      <td>0.580907</td>\n      <td>1.128879</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.512286</td>\n      <td>-1.414357</td>\n      <td>-1.823322</td>\n      <td>-0.082763</td>\n      <td>-0.184119</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-10.835207</td>\n      <td>-0.002704</td>\n      <td>-0.621836</td>\n      <td>NaN</td>\n      <td>1.172836</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.625862</td>\n      <td>NaN</td>\n      <td>-1.410017</td>\n      <td>1.063013</td>\n      <td>NaN</td>\n      <td>0.888355</td>\n      <td>0.467994</td>\n      <td>-1.36224</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.065759</td>\n      <td>0.013322</td>\n      <td>-0.592855</td>\n      <td>-1.052685</td>\n      <td>-0.393726</td>\n      <td>-0.741603</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.281207</td>\n      <td>-0.182894</td>\n      <td>-0.245565</td>\n      <td>-0.302441</td>\n      <td>2.965889</td>\n      <td>1.190077</td>\n      <td>-0.523998</td>\n      <td>3.849921</td>\n      <td>2.626981</td>\n      <td>5.000000</td>\n      <td>0.703665</td>\n      <td>0.216683</td>\n      <td>0.778639</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2.285698</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.056285</td>\n      <td>0.187227</td>\n      <td>0.249901</td>\n      <td>-0.773050</td>\n      <td>11</td>\n      <td>7</td>\n      <td>76</td>\n      <td>-0.675719</td>\n      <td>-0.199404</td>\n      <td>-0.586798</td>\n      <td>NaN</td>\n      <td>-0.814909</td>\n      <td>NaN</td>\n      <td>-1.296782</td>\n      <td>-2.040234</td>\n      <td>0.639589</td>\n      <td>NaN</td>\n      <td>1.597359</td>\n      <td>0.657514</td>\n      <td>-1.350148</td>\n      <td>0.364215</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.017751</td>\n      <td>-0.317361</td>\n      <td>-0.122379</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.320921</td>\n      <td>-0.958090</td>\n      <td>-2.436589</td>\n      <td>0.070999</td>\n      <td>-0.245239</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.420632</td>\n      <td>-3.515137</td>\n      <td>-4.677760</td>\n      <td>NaN</td>\n      <td>0.535897</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.725420</td>\n      <td>NaN</td>\n      <td>-2.294170</td>\n      <td>1.764551</td>\n      <td>NaN</td>\n      <td>-0.120789</td>\n      <td>-0.063458</td>\n      <td>-1.36224</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.882604</td>\n      <td>-0.072482</td>\n      <td>-0.617934</td>\n      <td>-0.863230</td>\n      <td>-0.241892</td>\n      <td>-0.709919</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.377131</td>\n      <td>0.300724</td>\n      <td>-0.106842</td>\n      <td>-0.096792</td>\n      <td>-0.864488</td>\n      <td>-0.280303</td>\n      <td>-0.326697</td>\n      <td>0.375781</td>\n      <td>1.271291</td>\n      <td>0.099793</td>\n      <td>2.109352</td>\n      <td>0.670881</td>\n      <td>0.772828</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.690606</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.139366</td>\n      <td>0.273328</td>\n      <td>0.306549</td>\n      <td>-1.262223</td>\n      <td>42</td>\n      <td>5</td>\n      <td>150</td>\n      <td>-0.694008</td>\n      <td>3.004091</td>\n      <td>0.114809</td>\n      <td>NaN</td>\n      <td>-0.251882</td>\n      <td>NaN</td>\n      <td>-1.902009</td>\n      <td>-0.979447</td>\n      <td>0.241165</td>\n      <td>NaN</td>\n      <td>-0.392359</td>\n      <td>-0.224699</td>\n      <td>-2.129397</td>\n      <td>-0.855287</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.404142</td>\n      <td>-0.578156</td>\n      <td>0.105702</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.544138</td>\n      <td>-0.087091</td>\n      <td>-1.500147</td>\n      <td>-0.201288</td>\n      <td>-0.038042</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.382074</td>\n      <td>2.669135</td>\n      <td>0.611711</td>\n      <td>NaN</td>\n      <td>2.413415</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.313203</td>\n      <td>NaN</td>\n      <td>-0.810125</td>\n      <td>2.939022</td>\n      <td>NaN</td>\n      <td>3.988801</td>\n      <td>1.834661</td>\n      <td>-1.36224</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.697595</td>\n      <td>1.074309</td>\n      <td>-0.206929</td>\n      <td>-0.530602</td>\n      <td>4.765215</td>\n      <td>0.571554</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.226891</td>\n      <td>-0.251412</td>\n      <td>-0.215522</td>\n      <td>-0.296244</td>\n      <td>0.408499</td>\n      <td>0.223992</td>\n      <td>2.294888</td>\n      <td>1.097444</td>\n      <td>1.225872</td>\n      <td>1.225376</td>\n      <td>1.114137</td>\n      <td>0.775199</td>\n      <td>-1.379516</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0.440570</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.955200</td>\n      <td>0.262404</td>\n      <td>0.344457</td>\n      <td>-0.613813</td>\n      <td>44</td>\n      <td>3</td>\n      <td>16</td>\n      <td>-0.947351</td>\n      <td>-0.030018</td>\n      <td>-0.502379</td>\n      <td>NaN</td>\n      <td>0.646086</td>\n      <td>NaN</td>\n      <td>-1.844685</td>\n      <td>-1.586560</td>\n      <td>-0.182024</td>\n      <td>NaN</td>\n      <td>-0.969949</td>\n      <td>-0.673813</td>\n      <td>-1.282132</td>\n      <td>-1.399894</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.043815</td>\n      <td>-0.320225</td>\n      <td>-0.031713</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.088420</td>\n      <td>-0.995003</td>\n      <td>-2.635336</td>\n      <td>-0.196461</td>\n      <td>-0.618719</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-2.014600</td>\n      <td>-2.321076</td>\n      <td>-3.711265</td>\n      <td>NaN</td>\n      <td>1.253902</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.476195</td>\n      <td>NaN</td>\n      <td>-0.771732</td>\n      <td>2.843421</td>\n      <td>NaN</td>\n      <td>1.379815</td>\n      <td>0.411827</td>\n      <td>-1.36224</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.948601</td>\n      <td>-0.136814</td>\n      <td>-0.447704</td>\n      <td>-1.141761</td>\n      <td>0.099631</td>\n      <td>-0.661928</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.678076</td>\n      <td>2.793581</td>\n      <td>2.618250</td>\n      <td>3.418133</td>\n      <td>-0.373387</td>\n      <td>-0.502764</td>\n      <td>-0.348021</td>\n      <td>-3.928148</td>\n      <td>-1.591366</td>\n      <td>-5.000000</td>\n      <td>-3.572820</td>\n      <td>-1.089123</td>\n      <td>-5.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## We sample 1% of the data by \"date_id\"\nThe original data size is exceedingly large and we do not have the computation power to train model on that. Thus we sample 1% of data grouped by \"date_id\" to do our initial training. After we build models based on this sampled dataset, we will refine our models using larger data if we have time.\n\nWe sample the data by \"data_id\" for the background setting of this competition. All the data are about finacial instruments and transactions. For that reason, we believe that sampling by date will give us a good representation of the original data.","metadata":{}},{"cell_type":"code","source":"def sample_data(df, frac):\n    # Group by the 'date_id' and sample \n    return df.groupby('date_id').sample(frac = frac).reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-30T17:02:17.554766Z","iopub.execute_input":"2024-11-30T17:02:17.555146Z","iopub.status.idle":"2024-11-30T17:02:17.562215Z","shell.execute_reply.started":"2024-11-30T17:02:17.555114Z","shell.execute_reply":"2024-11-30T17:02:17.560239Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"data_frames = [train_file_0, train_file_1, train_file_2, train_file_3, train_file_4,\n               train_file_5, train_file_6, train_file_7, train_file_8, train_file_9]\nsampled_data_frames = [sample_data(df,0.01) for df in data_frames]\nfinal_sampled_data = pd.concat(sampled_data_frames, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T17:03:03.302053Z","iopub.execute_input":"2024-11-30T17:03:03.302571Z","iopub.status.idle":"2024-11-30T17:03:21.705052Z","shell.execute_reply.started":"2024-11-30T17:03:03.302529Z","shell.execute_reply":"2024-11-30T17:03:21.701641Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"final_sampled_data","metadata":{"execution":{"iopub.status.busy":"2024-11-30T17:04:47.985416Z","iopub.execute_input":"2024-11-30T17:04:47.985858Z","iopub.status.idle":"2024-11-30T17:04:48.063149Z","shell.execute_reply.started":"2024-11-30T17:04:47.985821Z","shell.execute_reply":"2024-11-30T17:04:48.061980Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        date_id  time_id  symbol_id    weight  feature_00  feature_01  \\\n0             0      571          1  3.889038         NaN         NaN   \n1             0      215         19  2.456331         NaN         NaN   \n2             0      128         16  1.118269         NaN         NaN   \n3             0      642         10  0.690606         NaN         NaN   \n4             0      141         33  1.663408         NaN         NaN   \n...         ...      ...        ...       ...         ...         ...   \n471481     1698      874         13  2.048854    1.729690   -1.771553   \n471482     1698      767         16  3.511533    2.151929    0.419084   \n471483     1698      113         38  3.193685    2.094916    0.234795   \n471484     1698      122         19  4.964283    2.359492    0.214668   \n471485     1698       97          3  2.638314    2.065144    0.340648   \n\n        feature_02  feature_03  feature_04  feature_05  feature_06  \\\n0              NaN         NaN         NaN   -0.171507   -0.618816   \n1              NaN         NaN         NaN   -0.127892   -0.113770   \n2              NaN         NaN         NaN    0.141712    0.191647   \n3              NaN         NaN         NaN   -0.652387    0.046285   \n4              NaN         NaN         NaN    0.178329   -0.075612   \n...            ...         ...         ...         ...         ...   \n471481    2.231036    2.512293   -1.344412   -3.472090    1.463208   \n471482    2.067553    1.844757    0.106010   -0.044046    0.089718   \n471483    1.705341    2.011524   -0.347815    0.946882   -0.405801   \n471484    2.016579    2.311872    0.878478    0.498555   -0.181539   \n471485    2.099706    1.524543   -0.739278    0.818042    0.861297   \n\n        feature_07  feature_08  feature_09  feature_10  feature_11  \\\n0        -0.599811   -1.049087          11           7          76   \n1        -0.379178   -0.436973           4           3          11   \n2        -0.086295   -0.625996          11           7          76   \n3        -0.349272   -0.752097          42           5         150   \n4         0.033543   -1.074570          11           7          76   \n...            ...         ...         ...         ...         ...   \n471481   -0.849680    0.887388          50           1         522   \n471482   -0.084396   -0.138182          11           7          76   \n471483    0.506106   -0.494075          50           1         522   \n471484   -0.304325   -0.349200           4           3          11   \n471485    1.103488   -0.316168           4           3          11   \n\n        feature_12  feature_13  feature_14  feature_15  feature_16  \\\n0        -1.027201   -0.315285   -0.966018    0.244971    0.927985   \n1        -0.203073   -0.504336   -0.615524    0.189007    0.104171   \n2        -0.402947   -0.514509   -0.562865    0.286527    2.032491   \n3        -0.591007   -0.088429   -0.426924   -0.078154   -0.887051   \n4        -0.412069   -0.385492   -0.204645    0.971578    0.825604   \n...            ...         ...         ...         ...         ...   \n471481    0.370271   -0.047418    1.095776   -0.753097   -0.717464   \n471482   -0.093989   -0.050793    0.105754   -0.504411   -0.619086   \n471483   -0.181900   -0.316691   -0.060057   -0.855144   -0.986830   \n471484   -0.031933   -0.042529   -0.169148   -0.679774   -0.391265   \n471485   -0.012982   -0.220087   -0.195915   -0.766331   -0.661195   \n\n        feature_17  feature_18  feature_19  feature_20  feature_21  \\\n0         0.561707    0.017270   -0.097065    0.910130         NaN   \n1         0.396401   -0.588994    0.239663    0.105461         NaN   \n2         0.463615   -0.345060   -0.582428    0.748643         NaN   \n3        -0.038638    0.873007   -0.567895    0.241165         NaN   \n4         1.108364   -1.012509   -0.168201    0.679352         NaN   \n...            ...         ...         ...         ...         ...   \n471481   -0.380553    0.267900    1.120525    0.188037   -0.003101   \n471482   -0.774604   -1.147771    0.233700    1.655843   -0.061361   \n471483   -0.724856   -0.591208    0.024849   -0.440974   -0.072018   \n471484   -0.597164   -0.626287    0.097115    0.021237   -0.042261   \n471485   -0.750017   -0.322234    0.210781   -0.185432   -0.032784   \n\n        feature_22  feature_23  feature_24  feature_25  feature_26  \\\n0         1.636431    1.522133   -1.551398   -0.229627         NaN   \n1         0.946351    1.344925   -0.573883    0.964037         NaN   \n2         0.369530    0.748203   -1.476237   -0.098337         NaN   \n3        -0.392359   -0.224699   -2.129397   -0.855287         NaN   \n4         0.767303    0.740793   -1.215067   -1.124142         NaN   \n...            ...         ...         ...         ...         ...   \n471481    0.142380    0.550107    0.158455   -0.436337    3.619649   \n471482    1.784431    1.331869    0.938268    0.536201   -0.657209   \n471483    1.741353    1.380735   -0.110494   -0.874806    0.553424   \n471484    1.792063    1.740623    0.235926   -0.205855    0.554158   \n471485    0.513848    0.911167    0.139900   -0.494777   -0.010124   \n\n        feature_27  feature_28  feature_29  feature_30  feature_31  \\\n0              NaN    1.378301   -0.283712    0.123196         NaN   \n1              NaN   -0.616086    0.142924    0.266898         NaN   \n2              NaN    0.276082    0.108393    0.762983         NaN   \n3              NaN    0.404142   -0.578156    0.105702         NaN   \n4              NaN   -0.462220    0.263958    1.038144         NaN   \n...            ...         ...         ...         ...         ...   \n471481   -0.383218   -1.434520   -0.579597   -0.749147   -0.002427   \n471482    0.584148    1.005504   -0.594820   -0.942611   -0.054635   \n471483    0.532243    0.263214   -0.757856   -0.869204   -0.062955   \n471484    1.093280    1.389925   -0.506655   -0.550083   -0.095118   \n471485   -0.061895   -0.303735   -0.851368   -0.481167   -0.043368   \n\n        feature_32  feature_33  feature_34  feature_35  feature_36  \\\n0         0.259941    0.959155    0.111590    0.218147    0.163185   \n1         0.998232    0.805265   -0.252228   -0.198031   -0.175823   \n2         0.337653    1.983965    0.490731    0.806509    0.150105   \n3         0.479636   -0.508948    0.388735    0.433113    1.295252   \n4        -0.024072    0.747285   -0.086512    0.052809    0.226749   \n...            ...         ...         ...         ...         ...   \n471481    3.428646   -1.022624    3.136007    3.509312   -0.489627   \n471482    2.759396    0.354428    3.101874    2.342977   -1.274416   \n471483    3.212020    0.805771    2.677112    3.472906   -0.157318   \n471484    3.140806    1.115751    2.874091    3.436795    0.803590   \n471485    2.659252    0.757437    3.488509    3.207580   -0.391527   \n\n        feature_37  feature_38  feature_39  feature_40  feature_41  \\\n0        -0.167336   -0.331696    0.261165    0.596303    0.654964   \n1        -0.020167   -0.605129   -1.440532   -0.601468   -1.771672   \n2         0.066388   -0.348648   -1.613488   -1.454837   -1.684626   \n3         0.203897    0.260570   -0.514251   -2.264613   -1.857348   \n4        -0.218760   -0.683543         NaN         NaN         NaN   \n...            ...         ...         ...         ...         ...   \n471481    0.300941    0.024423   -0.158158    0.645422    0.866979   \n471482   -0.183876   -0.352525   -0.097883   -0.484755   -0.541919   \n471483   -0.085974   -0.172007    0.609608   -0.275591   -0.209530   \n471484   -0.241199   -0.268806   -0.248686   -0.017933   -0.243288   \n471485   -0.360606   -0.320272    1.454306   -0.051153    0.141915   \n\n        feature_42  feature_43  feature_44  feature_45  feature_46  \\\n0         1.780474    1.314882    1.546958   -0.000279    1.545038   \n1        -0.567503   -1.353847   -0.594302   -0.161477    0.428299   \n2        -0.708799   -1.382177   -0.951230   -0.164585    0.406057   \n3        -1.238543   -2.107757   -2.188823   -0.204171   -0.140535   \n4              NaN         NaN         NaN         NaN         NaN   \n...            ...         ...         ...         ...         ...   \n471481   -2.109370    0.613068   -1.379717   -1.118752   -1.018379   \n471482   -1.056681   -0.125479   -1.089042   -0.525229   -0.455905   \n471483    0.440458   -0.093966   -0.955189   -0.504238    0.824669   \n471484   -0.204660    0.766235   -0.228610   -0.290865    1.049525   \n471485    0.986178    0.335748    0.360685    0.528155    2.050340   \n\n        feature_47  feature_48  feature_49  feature_50  feature_51  \\\n0         0.151038   -0.003078   -0.012574   -1.737824   -0.073219   \n1         0.089409   -0.165432   -0.072996    0.353507   -0.071082   \n2         0.762846   -0.004109   -0.040363   -0.103097   -1.894952   \n3        -0.217525   -0.155155   -0.209023   -2.507159   -1.723807   \n4         0.486937   -0.004225    0.256216    0.814387    0.773077   \n...            ...         ...         ...         ...         ...   \n471481   -1.911348    0.449291   -0.709095   -0.609681    0.000356   \n471482   -0.658406   -0.043585   -0.798245   -1.302605   -0.713298   \n471483    0.492471   -0.371581    0.233755    0.542743   -0.280668   \n471484    0.506039    0.327954   -0.013669   -0.438969   -0.185639   \n471485    0.650057    0.268742    0.564619    1.618794   -0.226076   \n\n        feature_52  feature_53  feature_54  feature_55  feature_56  \\\n0        -0.210562    0.952181   -1.356518   -0.358807   -0.157291   \n1        -0.617008    0.295812   -1.072687   -0.195935   -0.334076   \n2         0.319757    0.343447   -0.475014    0.919373   -0.591895   \n3        -2.281412    0.052588   -0.276396    0.614121   -0.657207   \n4        -0.056389    0.075166   -1.436569   -0.716295    0.337179   \n...            ...         ...         ...         ...         ...   \n471481    0.222437   -1.800078    0.541373   -0.071597   -1.617990   \n471482    0.044910   -1.003529    0.570270   -0.799637   -0.162590   \n471483    0.101259    0.530800    0.036724    0.059855   -0.725768   \n471484   -0.910449    0.119061    0.359417   -0.865707   -0.748131   \n471485    0.185096    2.005779    0.240895    1.482874    0.068855   \n\n        feature_57  feature_58  feature_59  feature_60  feature_61  \\\n0         0.115600   -0.062861   -0.444003   -0.186445   -1.362240   \n1         0.125774    0.010350    0.005237    0.007209   -1.362240   \n2         0.261119   -0.129354    0.011765    0.046140   -1.362240   \n3        -0.390522   -0.592689   -0.568269   -0.691580   -1.362240   \n4        -0.060814    0.269631   -0.051234    0.229287   -1.362240   \n...            ...         ...         ...         ...         ...   \n471481   -1.192304   -2.427584    0.316568   -0.958952   -1.101531   \n471482   -0.242842   -0.918514    0.011834   -0.704797   -1.101531   \n471483    1.543792    0.503177   -0.423436    0.390717   -1.101531   \n471484    1.262201    0.248428   -0.246701   -0.327218   -1.101531   \n471485    2.894062    0.902985    0.179325    1.035899   -1.101531   \n\n        feature_62  feature_63  feature_64  feature_65  feature_66  \\\n0        -0.097224    0.125202    0.073452    0.466931   -0.249663   \n1        -0.409740    0.009257   -0.298328   -1.032182   -0.063632   \n2         0.205827    0.104350    0.272482   -0.490489    0.041345   \n3         0.242599    0.020648   -0.034992    0.803539   -0.613457   \n4              NaN         NaN         NaN         NaN         NaN   \n...            ...         ...         ...         ...         ...   \n471481   -0.437864   -0.301658   -0.495174    2.130961    1.703359   \n471482   -0.472057   -0.370296   -0.433566   -1.339241    0.292552   \n471483   -0.406076   -0.517795   -0.399147   -0.879348    0.296820   \n471484   -0.501064   -0.466125   -0.304120   -0.571045   -0.322801   \n471485   -0.494085   -0.462855   -0.283053   -1.160801    0.214611   \n\n        feature_67  feature_68  feature_69  feature_70  feature_71  \\\n0        -0.919615   -0.428662   -0.599638   -0.728244   -0.302370   \n1        -0.146893   -0.327029   -0.613035   -0.223287   -0.397794   \n2        -0.201421   -0.371349   -0.564927   -0.365174   -0.399971   \n3        -0.364276    0.143600   -0.153347   -0.793435   -0.414147   \n4        -0.341160   -0.501883   -0.547881   -0.354556   -0.262720   \n...            ...         ...         ...         ...         ...   \n471481    0.753005    0.023931    1.568034   -0.119650   -0.106162   \n471482   -0.041987   -0.173592    0.161309   -0.202686    0.125780   \n471483   -0.526542   -0.291092   -0.355316   -0.112644   -0.197700   \n471484   -0.154297    0.077113   -0.107053    0.140711   -0.132216   \n471485   -0.121244   -0.272672   -0.286454    0.093911    0.003435   \n\n        feature_72  feature_73  feature_74  feature_75  feature_76  \\\n0        -0.911423   -0.366531   -0.311020   -0.402565   -0.261819   \n1        -0.695375   -0.424535   -0.304591   -0.294916   -0.311847   \n2        -0.741666   -0.434856   -0.381427   -0.246326   -0.223045   \n3        -0.398652   -0.231816   -0.152974   -0.150202   -0.160602   \n4        -0.405531   -0.295525   -0.219786   -0.187691   -0.191829   \n...            ...         ...         ...         ...         ...   \n471481    0.196181   -0.183356   -0.458089   -0.221024   -0.155208   \n471482    0.029913   -0.361390   -0.256281   -0.196249   -0.228376   \n471483    0.311768   -0.304444   -0.383219   -0.266505   -0.290321   \n471484   -0.146833   -0.224121   -0.214002   -0.165984   -0.130209   \n471485   -0.002958   -0.155674   -0.177065    0.016265    0.051879   \n\n        feature_77  feature_78  responder_0  responder_1  responder_2  \\\n0        -0.217682   -0.328652     0.098423     0.387570     0.670622   \n1        -0.249188   -0.225042     0.174137     0.095463    -0.854110   \n2        -0.356662   -0.254885    -0.132599     0.111260     0.003097   \n3        -0.244379   -0.274058    -0.032792    -0.523904    -0.009532   \n4        -0.242459   -0.323666     0.106548    -1.310868     0.178857   \n...            ...         ...          ...          ...          ...   \n471481   -0.236381   -0.229434    -0.122475     1.906371     0.157266   \n471482   -0.207773   -0.368578    -0.316808     0.046898    -0.287612   \n471483   -0.413458   -0.246880     0.165272     0.064522     0.264797   \n471484   -0.192047   -0.160750     0.258129    -0.037723     0.832549   \n471485    0.028640    0.051529    -0.451928    -0.028827    -0.388385   \n\n        responder_3  responder_4  responder_5  responder_6  responder_7  \\\n0         -0.099852     0.357261     0.000500    -0.224964    -0.045573   \n1          0.285258    -0.069922    -0.293819     0.239918    -0.172197   \n2         -0.025234    -1.263809    -0.034224     0.100815    -1.021730   \n3         -2.114564    -1.589038     0.095437    -0.303095    -0.934571   \n4         -2.358691    -1.343145    -3.206770    -0.217588    -0.564157   \n...             ...          ...          ...          ...          ...   \n471481    -0.048255     1.331458     0.019048    -0.016280     2.161790   \n471482    -0.946852    -0.723157    -0.324245    -1.040491    -0.699566   \n471483     1.428663     0.862083     0.192335     1.674319     0.695484   \n471484     0.031166    -0.665050     0.024743    -0.131535    -0.877966   \n471485    -0.456334    -0.188195    -0.745907    -0.197484    -0.235763   \n\n        responder_8  \n0         -0.934438  \n1          0.284304  \n2         -0.033107  \n3          0.256316  \n4          0.064031  \n...             ...  \n471481    -0.089303  \n471482    -0.255916  \n471483     0.193396  \n471484    -0.552370  \n471485    -0.624066  \n\n[471486 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>time_id</th>\n      <th>symbol_id</th>\n      <th>weight</th>\n      <th>feature_00</th>\n      <th>feature_01</th>\n      <th>feature_02</th>\n      <th>feature_03</th>\n      <th>feature_04</th>\n      <th>feature_05</th>\n      <th>feature_06</th>\n      <th>feature_07</th>\n      <th>feature_08</th>\n      <th>feature_09</th>\n      <th>feature_10</th>\n      <th>feature_11</th>\n      <th>feature_12</th>\n      <th>feature_13</th>\n      <th>feature_14</th>\n      <th>feature_15</th>\n      <th>feature_16</th>\n      <th>feature_17</th>\n      <th>feature_18</th>\n      <th>feature_19</th>\n      <th>feature_20</th>\n      <th>feature_21</th>\n      <th>feature_22</th>\n      <th>feature_23</th>\n      <th>feature_24</th>\n      <th>feature_25</th>\n      <th>feature_26</th>\n      <th>feature_27</th>\n      <th>feature_28</th>\n      <th>feature_29</th>\n      <th>feature_30</th>\n      <th>feature_31</th>\n      <th>feature_32</th>\n      <th>feature_33</th>\n      <th>feature_34</th>\n      <th>feature_35</th>\n      <th>feature_36</th>\n      <th>feature_37</th>\n      <th>feature_38</th>\n      <th>feature_39</th>\n      <th>feature_40</th>\n      <th>feature_41</th>\n      <th>feature_42</th>\n      <th>feature_43</th>\n      <th>feature_44</th>\n      <th>feature_45</th>\n      <th>feature_46</th>\n      <th>feature_47</th>\n      <th>feature_48</th>\n      <th>feature_49</th>\n      <th>feature_50</th>\n      <th>feature_51</th>\n      <th>feature_52</th>\n      <th>feature_53</th>\n      <th>feature_54</th>\n      <th>feature_55</th>\n      <th>feature_56</th>\n      <th>feature_57</th>\n      <th>feature_58</th>\n      <th>feature_59</th>\n      <th>feature_60</th>\n      <th>feature_61</th>\n      <th>feature_62</th>\n      <th>feature_63</th>\n      <th>feature_64</th>\n      <th>feature_65</th>\n      <th>feature_66</th>\n      <th>feature_67</th>\n      <th>feature_68</th>\n      <th>feature_69</th>\n      <th>feature_70</th>\n      <th>feature_71</th>\n      <th>feature_72</th>\n      <th>feature_73</th>\n      <th>feature_74</th>\n      <th>feature_75</th>\n      <th>feature_76</th>\n      <th>feature_77</th>\n      <th>feature_78</th>\n      <th>responder_0</th>\n      <th>responder_1</th>\n      <th>responder_2</th>\n      <th>responder_3</th>\n      <th>responder_4</th>\n      <th>responder_5</th>\n      <th>responder_6</th>\n      <th>responder_7</th>\n      <th>responder_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>571</td>\n      <td>1</td>\n      <td>3.889038</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.171507</td>\n      <td>-0.618816</td>\n      <td>-0.599811</td>\n      <td>-1.049087</td>\n      <td>11</td>\n      <td>7</td>\n      <td>76</td>\n      <td>-1.027201</td>\n      <td>-0.315285</td>\n      <td>-0.966018</td>\n      <td>0.244971</td>\n      <td>0.927985</td>\n      <td>0.561707</td>\n      <td>0.017270</td>\n      <td>-0.097065</td>\n      <td>0.910130</td>\n      <td>NaN</td>\n      <td>1.636431</td>\n      <td>1.522133</td>\n      <td>-1.551398</td>\n      <td>-0.229627</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.378301</td>\n      <td>-0.283712</td>\n      <td>0.123196</td>\n      <td>NaN</td>\n      <td>0.259941</td>\n      <td>0.959155</td>\n      <td>0.111590</td>\n      <td>0.218147</td>\n      <td>0.163185</td>\n      <td>-0.167336</td>\n      <td>-0.331696</td>\n      <td>0.261165</td>\n      <td>0.596303</td>\n      <td>0.654964</td>\n      <td>1.780474</td>\n      <td>1.314882</td>\n      <td>1.546958</td>\n      <td>-0.000279</td>\n      <td>1.545038</td>\n      <td>0.151038</td>\n      <td>-0.003078</td>\n      <td>-0.012574</td>\n      <td>-1.737824</td>\n      <td>-0.073219</td>\n      <td>-0.210562</td>\n      <td>0.952181</td>\n      <td>-1.356518</td>\n      <td>-0.358807</td>\n      <td>-0.157291</td>\n      <td>0.115600</td>\n      <td>-0.062861</td>\n      <td>-0.444003</td>\n      <td>-0.186445</td>\n      <td>-1.362240</td>\n      <td>-0.097224</td>\n      <td>0.125202</td>\n      <td>0.073452</td>\n      <td>0.466931</td>\n      <td>-0.249663</td>\n      <td>-0.919615</td>\n      <td>-0.428662</td>\n      <td>-0.599638</td>\n      <td>-0.728244</td>\n      <td>-0.302370</td>\n      <td>-0.911423</td>\n      <td>-0.366531</td>\n      <td>-0.311020</td>\n      <td>-0.402565</td>\n      <td>-0.261819</td>\n      <td>-0.217682</td>\n      <td>-0.328652</td>\n      <td>0.098423</td>\n      <td>0.387570</td>\n      <td>0.670622</td>\n      <td>-0.099852</td>\n      <td>0.357261</td>\n      <td>0.000500</td>\n      <td>-0.224964</td>\n      <td>-0.045573</td>\n      <td>-0.934438</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>215</td>\n      <td>19</td>\n      <td>2.456331</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.127892</td>\n      <td>-0.113770</td>\n      <td>-0.379178</td>\n      <td>-0.436973</td>\n      <td>4</td>\n      <td>3</td>\n      <td>11</td>\n      <td>-0.203073</td>\n      <td>-0.504336</td>\n      <td>-0.615524</td>\n      <td>0.189007</td>\n      <td>0.104171</td>\n      <td>0.396401</td>\n      <td>-0.588994</td>\n      <td>0.239663</td>\n      <td>0.105461</td>\n      <td>NaN</td>\n      <td>0.946351</td>\n      <td>1.344925</td>\n      <td>-0.573883</td>\n      <td>0.964037</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.616086</td>\n      <td>0.142924</td>\n      <td>0.266898</td>\n      <td>NaN</td>\n      <td>0.998232</td>\n      <td>0.805265</td>\n      <td>-0.252228</td>\n      <td>-0.198031</td>\n      <td>-0.175823</td>\n      <td>-0.020167</td>\n      <td>-0.605129</td>\n      <td>-1.440532</td>\n      <td>-0.601468</td>\n      <td>-1.771672</td>\n      <td>-0.567503</td>\n      <td>-1.353847</td>\n      <td>-0.594302</td>\n      <td>-0.161477</td>\n      <td>0.428299</td>\n      <td>0.089409</td>\n      <td>-0.165432</td>\n      <td>-0.072996</td>\n      <td>0.353507</td>\n      <td>-0.071082</td>\n      <td>-0.617008</td>\n      <td>0.295812</td>\n      <td>-1.072687</td>\n      <td>-0.195935</td>\n      <td>-0.334076</td>\n      <td>0.125774</td>\n      <td>0.010350</td>\n      <td>0.005237</td>\n      <td>0.007209</td>\n      <td>-1.362240</td>\n      <td>-0.409740</td>\n      <td>0.009257</td>\n      <td>-0.298328</td>\n      <td>-1.032182</td>\n      <td>-0.063632</td>\n      <td>-0.146893</td>\n      <td>-0.327029</td>\n      <td>-0.613035</td>\n      <td>-0.223287</td>\n      <td>-0.397794</td>\n      <td>-0.695375</td>\n      <td>-0.424535</td>\n      <td>-0.304591</td>\n      <td>-0.294916</td>\n      <td>-0.311847</td>\n      <td>-0.249188</td>\n      <td>-0.225042</td>\n      <td>0.174137</td>\n      <td>0.095463</td>\n      <td>-0.854110</td>\n      <td>0.285258</td>\n      <td>-0.069922</td>\n      <td>-0.293819</td>\n      <td>0.239918</td>\n      <td>-0.172197</td>\n      <td>0.284304</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>128</td>\n      <td>16</td>\n      <td>1.118269</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.141712</td>\n      <td>0.191647</td>\n      <td>-0.086295</td>\n      <td>-0.625996</td>\n      <td>11</td>\n      <td>7</td>\n      <td>76</td>\n      <td>-0.402947</td>\n      <td>-0.514509</td>\n      <td>-0.562865</td>\n      <td>0.286527</td>\n      <td>2.032491</td>\n      <td>0.463615</td>\n      <td>-0.345060</td>\n      <td>-0.582428</td>\n      <td>0.748643</td>\n      <td>NaN</td>\n      <td>0.369530</td>\n      <td>0.748203</td>\n      <td>-1.476237</td>\n      <td>-0.098337</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.276082</td>\n      <td>0.108393</td>\n      <td>0.762983</td>\n      <td>NaN</td>\n      <td>0.337653</td>\n      <td>1.983965</td>\n      <td>0.490731</td>\n      <td>0.806509</td>\n      <td>0.150105</td>\n      <td>0.066388</td>\n      <td>-0.348648</td>\n      <td>-1.613488</td>\n      <td>-1.454837</td>\n      <td>-1.684626</td>\n      <td>-0.708799</td>\n      <td>-1.382177</td>\n      <td>-0.951230</td>\n      <td>-0.164585</td>\n      <td>0.406057</td>\n      <td>0.762846</td>\n      <td>-0.004109</td>\n      <td>-0.040363</td>\n      <td>-0.103097</td>\n      <td>-1.894952</td>\n      <td>0.319757</td>\n      <td>0.343447</td>\n      <td>-0.475014</td>\n      <td>0.919373</td>\n      <td>-0.591895</td>\n      <td>0.261119</td>\n      <td>-0.129354</td>\n      <td>0.011765</td>\n      <td>0.046140</td>\n      <td>-1.362240</td>\n      <td>0.205827</td>\n      <td>0.104350</td>\n      <td>0.272482</td>\n      <td>-0.490489</td>\n      <td>0.041345</td>\n      <td>-0.201421</td>\n      <td>-0.371349</td>\n      <td>-0.564927</td>\n      <td>-0.365174</td>\n      <td>-0.399971</td>\n      <td>-0.741666</td>\n      <td>-0.434856</td>\n      <td>-0.381427</td>\n      <td>-0.246326</td>\n      <td>-0.223045</td>\n      <td>-0.356662</td>\n      <td>-0.254885</td>\n      <td>-0.132599</td>\n      <td>0.111260</td>\n      <td>0.003097</td>\n      <td>-0.025234</td>\n      <td>-1.263809</td>\n      <td>-0.034224</td>\n      <td>0.100815</td>\n      <td>-1.021730</td>\n      <td>-0.033107</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>642</td>\n      <td>10</td>\n      <td>0.690606</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.652387</td>\n      <td>0.046285</td>\n      <td>-0.349272</td>\n      <td>-0.752097</td>\n      <td>42</td>\n      <td>5</td>\n      <td>150</td>\n      <td>-0.591007</td>\n      <td>-0.088429</td>\n      <td>-0.426924</td>\n      <td>-0.078154</td>\n      <td>-0.887051</td>\n      <td>-0.038638</td>\n      <td>0.873007</td>\n      <td>-0.567895</td>\n      <td>0.241165</td>\n      <td>NaN</td>\n      <td>-0.392359</td>\n      <td>-0.224699</td>\n      <td>-2.129397</td>\n      <td>-0.855287</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.404142</td>\n      <td>-0.578156</td>\n      <td>0.105702</td>\n      <td>NaN</td>\n      <td>0.479636</td>\n      <td>-0.508948</td>\n      <td>0.388735</td>\n      <td>0.433113</td>\n      <td>1.295252</td>\n      <td>0.203897</td>\n      <td>0.260570</td>\n      <td>-0.514251</td>\n      <td>-2.264613</td>\n      <td>-1.857348</td>\n      <td>-1.238543</td>\n      <td>-2.107757</td>\n      <td>-2.188823</td>\n      <td>-0.204171</td>\n      <td>-0.140535</td>\n      <td>-0.217525</td>\n      <td>-0.155155</td>\n      <td>-0.209023</td>\n      <td>-2.507159</td>\n      <td>-1.723807</td>\n      <td>-2.281412</td>\n      <td>0.052588</td>\n      <td>-0.276396</td>\n      <td>0.614121</td>\n      <td>-0.657207</td>\n      <td>-0.390522</td>\n      <td>-0.592689</td>\n      <td>-0.568269</td>\n      <td>-0.691580</td>\n      <td>-1.362240</td>\n      <td>0.242599</td>\n      <td>0.020648</td>\n      <td>-0.034992</td>\n      <td>0.803539</td>\n      <td>-0.613457</td>\n      <td>-0.364276</td>\n      <td>0.143600</td>\n      <td>-0.153347</td>\n      <td>-0.793435</td>\n      <td>-0.414147</td>\n      <td>-0.398652</td>\n      <td>-0.231816</td>\n      <td>-0.152974</td>\n      <td>-0.150202</td>\n      <td>-0.160602</td>\n      <td>-0.244379</td>\n      <td>-0.274058</td>\n      <td>-0.032792</td>\n      <td>-0.523904</td>\n      <td>-0.009532</td>\n      <td>-2.114564</td>\n      <td>-1.589038</td>\n      <td>0.095437</td>\n      <td>-0.303095</td>\n      <td>-0.934571</td>\n      <td>0.256316</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>141</td>\n      <td>33</td>\n      <td>1.663408</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.178329</td>\n      <td>-0.075612</td>\n      <td>0.033543</td>\n      <td>-1.074570</td>\n      <td>11</td>\n      <td>7</td>\n      <td>76</td>\n      <td>-0.412069</td>\n      <td>-0.385492</td>\n      <td>-0.204645</td>\n      <td>0.971578</td>\n      <td>0.825604</td>\n      <td>1.108364</td>\n      <td>-1.012509</td>\n      <td>-0.168201</td>\n      <td>0.679352</td>\n      <td>NaN</td>\n      <td>0.767303</td>\n      <td>0.740793</td>\n      <td>-1.215067</td>\n      <td>-1.124142</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.462220</td>\n      <td>0.263958</td>\n      <td>1.038144</td>\n      <td>NaN</td>\n      <td>-0.024072</td>\n      <td>0.747285</td>\n      <td>-0.086512</td>\n      <td>0.052809</td>\n      <td>0.226749</td>\n      <td>-0.218760</td>\n      <td>-0.683543</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.486937</td>\n      <td>-0.004225</td>\n      <td>0.256216</td>\n      <td>0.814387</td>\n      <td>0.773077</td>\n      <td>-0.056389</td>\n      <td>0.075166</td>\n      <td>-1.436569</td>\n      <td>-0.716295</td>\n      <td>0.337179</td>\n      <td>-0.060814</td>\n      <td>0.269631</td>\n      <td>-0.051234</td>\n      <td>0.229287</td>\n      <td>-1.362240</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.341160</td>\n      <td>-0.501883</td>\n      <td>-0.547881</td>\n      <td>-0.354556</td>\n      <td>-0.262720</td>\n      <td>-0.405531</td>\n      <td>-0.295525</td>\n      <td>-0.219786</td>\n      <td>-0.187691</td>\n      <td>-0.191829</td>\n      <td>-0.242459</td>\n      <td>-0.323666</td>\n      <td>0.106548</td>\n      <td>-1.310868</td>\n      <td>0.178857</td>\n      <td>-2.358691</td>\n      <td>-1.343145</td>\n      <td>-3.206770</td>\n      <td>-0.217588</td>\n      <td>-0.564157</td>\n      <td>0.064031</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>471481</th>\n      <td>1698</td>\n      <td>874</td>\n      <td>13</td>\n      <td>2.048854</td>\n      <td>1.729690</td>\n      <td>-1.771553</td>\n      <td>2.231036</td>\n      <td>2.512293</td>\n      <td>-1.344412</td>\n      <td>-3.472090</td>\n      <td>1.463208</td>\n      <td>-0.849680</td>\n      <td>0.887388</td>\n      <td>50</td>\n      <td>1</td>\n      <td>522</td>\n      <td>0.370271</td>\n      <td>-0.047418</td>\n      <td>1.095776</td>\n      <td>-0.753097</td>\n      <td>-0.717464</td>\n      <td>-0.380553</td>\n      <td>0.267900</td>\n      <td>1.120525</td>\n      <td>0.188037</td>\n      <td>-0.003101</td>\n      <td>0.142380</td>\n      <td>0.550107</td>\n      <td>0.158455</td>\n      <td>-0.436337</td>\n      <td>3.619649</td>\n      <td>-0.383218</td>\n      <td>-1.434520</td>\n      <td>-0.579597</td>\n      <td>-0.749147</td>\n      <td>-0.002427</td>\n      <td>3.428646</td>\n      <td>-1.022624</td>\n      <td>3.136007</td>\n      <td>3.509312</td>\n      <td>-0.489627</td>\n      <td>0.300941</td>\n      <td>0.024423</td>\n      <td>-0.158158</td>\n      <td>0.645422</td>\n      <td>0.866979</td>\n      <td>-2.109370</td>\n      <td>0.613068</td>\n      <td>-1.379717</td>\n      <td>-1.118752</td>\n      <td>-1.018379</td>\n      <td>-1.911348</td>\n      <td>0.449291</td>\n      <td>-0.709095</td>\n      <td>-0.609681</td>\n      <td>0.000356</td>\n      <td>0.222437</td>\n      <td>-1.800078</td>\n      <td>0.541373</td>\n      <td>-0.071597</td>\n      <td>-1.617990</td>\n      <td>-1.192304</td>\n      <td>-2.427584</td>\n      <td>0.316568</td>\n      <td>-0.958952</td>\n      <td>-1.101531</td>\n      <td>-0.437864</td>\n      <td>-0.301658</td>\n      <td>-0.495174</td>\n      <td>2.130961</td>\n      <td>1.703359</td>\n      <td>0.753005</td>\n      <td>0.023931</td>\n      <td>1.568034</td>\n      <td>-0.119650</td>\n      <td>-0.106162</td>\n      <td>0.196181</td>\n      <td>-0.183356</td>\n      <td>-0.458089</td>\n      <td>-0.221024</td>\n      <td>-0.155208</td>\n      <td>-0.236381</td>\n      <td>-0.229434</td>\n      <td>-0.122475</td>\n      <td>1.906371</td>\n      <td>0.157266</td>\n      <td>-0.048255</td>\n      <td>1.331458</td>\n      <td>0.019048</td>\n      <td>-0.016280</td>\n      <td>2.161790</td>\n      <td>-0.089303</td>\n    </tr>\n    <tr>\n      <th>471482</th>\n      <td>1698</td>\n      <td>767</td>\n      <td>16</td>\n      <td>3.511533</td>\n      <td>2.151929</td>\n      <td>0.419084</td>\n      <td>2.067553</td>\n      <td>1.844757</td>\n      <td>0.106010</td>\n      <td>-0.044046</td>\n      <td>0.089718</td>\n      <td>-0.084396</td>\n      <td>-0.138182</td>\n      <td>11</td>\n      <td>7</td>\n      <td>76</td>\n      <td>-0.093989</td>\n      <td>-0.050793</td>\n      <td>0.105754</td>\n      <td>-0.504411</td>\n      <td>-0.619086</td>\n      <td>-0.774604</td>\n      <td>-1.147771</td>\n      <td>0.233700</td>\n      <td>1.655843</td>\n      <td>-0.061361</td>\n      <td>1.784431</td>\n      <td>1.331869</td>\n      <td>0.938268</td>\n      <td>0.536201</td>\n      <td>-0.657209</td>\n      <td>0.584148</td>\n      <td>1.005504</td>\n      <td>-0.594820</td>\n      <td>-0.942611</td>\n      <td>-0.054635</td>\n      <td>2.759396</td>\n      <td>0.354428</td>\n      <td>3.101874</td>\n      <td>2.342977</td>\n      <td>-1.274416</td>\n      <td>-0.183876</td>\n      <td>-0.352525</td>\n      <td>-0.097883</td>\n      <td>-0.484755</td>\n      <td>-0.541919</td>\n      <td>-1.056681</td>\n      <td>-0.125479</td>\n      <td>-1.089042</td>\n      <td>-0.525229</td>\n      <td>-0.455905</td>\n      <td>-0.658406</td>\n      <td>-0.043585</td>\n      <td>-0.798245</td>\n      <td>-1.302605</td>\n      <td>-0.713298</td>\n      <td>0.044910</td>\n      <td>-1.003529</td>\n      <td>0.570270</td>\n      <td>-0.799637</td>\n      <td>-0.162590</td>\n      <td>-0.242842</td>\n      <td>-0.918514</td>\n      <td>0.011834</td>\n      <td>-0.704797</td>\n      <td>-1.101531</td>\n      <td>-0.472057</td>\n      <td>-0.370296</td>\n      <td>-0.433566</td>\n      <td>-1.339241</td>\n      <td>0.292552</td>\n      <td>-0.041987</td>\n      <td>-0.173592</td>\n      <td>0.161309</td>\n      <td>-0.202686</td>\n      <td>0.125780</td>\n      <td>0.029913</td>\n      <td>-0.361390</td>\n      <td>-0.256281</td>\n      <td>-0.196249</td>\n      <td>-0.228376</td>\n      <td>-0.207773</td>\n      <td>-0.368578</td>\n      <td>-0.316808</td>\n      <td>0.046898</td>\n      <td>-0.287612</td>\n      <td>-0.946852</td>\n      <td>-0.723157</td>\n      <td>-0.324245</td>\n      <td>-1.040491</td>\n      <td>-0.699566</td>\n      <td>-0.255916</td>\n    </tr>\n    <tr>\n      <th>471483</th>\n      <td>1698</td>\n      <td>113</td>\n      <td>38</td>\n      <td>3.193685</td>\n      <td>2.094916</td>\n      <td>0.234795</td>\n      <td>1.705341</td>\n      <td>2.011524</td>\n      <td>-0.347815</td>\n      <td>0.946882</td>\n      <td>-0.405801</td>\n      <td>0.506106</td>\n      <td>-0.494075</td>\n      <td>50</td>\n      <td>1</td>\n      <td>522</td>\n      <td>-0.181900</td>\n      <td>-0.316691</td>\n      <td>-0.060057</td>\n      <td>-0.855144</td>\n      <td>-0.986830</td>\n      <td>-0.724856</td>\n      <td>-0.591208</td>\n      <td>0.024849</td>\n      <td>-0.440974</td>\n      <td>-0.072018</td>\n      <td>1.741353</td>\n      <td>1.380735</td>\n      <td>-0.110494</td>\n      <td>-0.874806</td>\n      <td>0.553424</td>\n      <td>0.532243</td>\n      <td>0.263214</td>\n      <td>-0.757856</td>\n      <td>-0.869204</td>\n      <td>-0.062955</td>\n      <td>3.212020</td>\n      <td>0.805771</td>\n      <td>2.677112</td>\n      <td>3.472906</td>\n      <td>-0.157318</td>\n      <td>-0.085974</td>\n      <td>-0.172007</td>\n      <td>0.609608</td>\n      <td>-0.275591</td>\n      <td>-0.209530</td>\n      <td>0.440458</td>\n      <td>-0.093966</td>\n      <td>-0.955189</td>\n      <td>-0.504238</td>\n      <td>0.824669</td>\n      <td>0.492471</td>\n      <td>-0.371581</td>\n      <td>0.233755</td>\n      <td>0.542743</td>\n      <td>-0.280668</td>\n      <td>0.101259</td>\n      <td>0.530800</td>\n      <td>0.036724</td>\n      <td>0.059855</td>\n      <td>-0.725768</td>\n      <td>1.543792</td>\n      <td>0.503177</td>\n      <td>-0.423436</td>\n      <td>0.390717</td>\n      <td>-1.101531</td>\n      <td>-0.406076</td>\n      <td>-0.517795</td>\n      <td>-0.399147</td>\n      <td>-0.879348</td>\n      <td>0.296820</td>\n      <td>-0.526542</td>\n      <td>-0.291092</td>\n      <td>-0.355316</td>\n      <td>-0.112644</td>\n      <td>-0.197700</td>\n      <td>0.311768</td>\n      <td>-0.304444</td>\n      <td>-0.383219</td>\n      <td>-0.266505</td>\n      <td>-0.290321</td>\n      <td>-0.413458</td>\n      <td>-0.246880</td>\n      <td>0.165272</td>\n      <td>0.064522</td>\n      <td>0.264797</td>\n      <td>1.428663</td>\n      <td>0.862083</td>\n      <td>0.192335</td>\n      <td>1.674319</td>\n      <td>0.695484</td>\n      <td>0.193396</td>\n    </tr>\n    <tr>\n      <th>471484</th>\n      <td>1698</td>\n      <td>122</td>\n      <td>19</td>\n      <td>4.964283</td>\n      <td>2.359492</td>\n      <td>0.214668</td>\n      <td>2.016579</td>\n      <td>2.311872</td>\n      <td>0.878478</td>\n      <td>0.498555</td>\n      <td>-0.181539</td>\n      <td>-0.304325</td>\n      <td>-0.349200</td>\n      <td>4</td>\n      <td>3</td>\n      <td>11</td>\n      <td>-0.031933</td>\n      <td>-0.042529</td>\n      <td>-0.169148</td>\n      <td>-0.679774</td>\n      <td>-0.391265</td>\n      <td>-0.597164</td>\n      <td>-0.626287</td>\n      <td>0.097115</td>\n      <td>0.021237</td>\n      <td>-0.042261</td>\n      <td>1.792063</td>\n      <td>1.740623</td>\n      <td>0.235926</td>\n      <td>-0.205855</td>\n      <td>0.554158</td>\n      <td>1.093280</td>\n      <td>1.389925</td>\n      <td>-0.506655</td>\n      <td>-0.550083</td>\n      <td>-0.095118</td>\n      <td>3.140806</td>\n      <td>1.115751</td>\n      <td>2.874091</td>\n      <td>3.436795</td>\n      <td>0.803590</td>\n      <td>-0.241199</td>\n      <td>-0.268806</td>\n      <td>-0.248686</td>\n      <td>-0.017933</td>\n      <td>-0.243288</td>\n      <td>-0.204660</td>\n      <td>0.766235</td>\n      <td>-0.228610</td>\n      <td>-0.290865</td>\n      <td>1.049525</td>\n      <td>0.506039</td>\n      <td>0.327954</td>\n      <td>-0.013669</td>\n      <td>-0.438969</td>\n      <td>-0.185639</td>\n      <td>-0.910449</td>\n      <td>0.119061</td>\n      <td>0.359417</td>\n      <td>-0.865707</td>\n      <td>-0.748131</td>\n      <td>1.262201</td>\n      <td>0.248428</td>\n      <td>-0.246701</td>\n      <td>-0.327218</td>\n      <td>-1.101531</td>\n      <td>-0.501064</td>\n      <td>-0.466125</td>\n      <td>-0.304120</td>\n      <td>-0.571045</td>\n      <td>-0.322801</td>\n      <td>-0.154297</td>\n      <td>0.077113</td>\n      <td>-0.107053</td>\n      <td>0.140711</td>\n      <td>-0.132216</td>\n      <td>-0.146833</td>\n      <td>-0.224121</td>\n      <td>-0.214002</td>\n      <td>-0.165984</td>\n      <td>-0.130209</td>\n      <td>-0.192047</td>\n      <td>-0.160750</td>\n      <td>0.258129</td>\n      <td>-0.037723</td>\n      <td>0.832549</td>\n      <td>0.031166</td>\n      <td>-0.665050</td>\n      <td>0.024743</td>\n      <td>-0.131535</td>\n      <td>-0.877966</td>\n      <td>-0.552370</td>\n    </tr>\n    <tr>\n      <th>471485</th>\n      <td>1698</td>\n      <td>97</td>\n      <td>3</td>\n      <td>2.638314</td>\n      <td>2.065144</td>\n      <td>0.340648</td>\n      <td>2.099706</td>\n      <td>1.524543</td>\n      <td>-0.739278</td>\n      <td>0.818042</td>\n      <td>0.861297</td>\n      <td>1.103488</td>\n      <td>-0.316168</td>\n      <td>4</td>\n      <td>3</td>\n      <td>11</td>\n      <td>-0.012982</td>\n      <td>-0.220087</td>\n      <td>-0.195915</td>\n      <td>-0.766331</td>\n      <td>-0.661195</td>\n      <td>-0.750017</td>\n      <td>-0.322234</td>\n      <td>0.210781</td>\n      <td>-0.185432</td>\n      <td>-0.032784</td>\n      <td>0.513848</td>\n      <td>0.911167</td>\n      <td>0.139900</td>\n      <td>-0.494777</td>\n      <td>-0.010124</td>\n      <td>-0.061895</td>\n      <td>-0.303735</td>\n      <td>-0.851368</td>\n      <td>-0.481167</td>\n      <td>-0.043368</td>\n      <td>2.659252</td>\n      <td>0.757437</td>\n      <td>3.488509</td>\n      <td>3.207580</td>\n      <td>-0.391527</td>\n      <td>-0.360606</td>\n      <td>-0.320272</td>\n      <td>1.454306</td>\n      <td>-0.051153</td>\n      <td>0.141915</td>\n      <td>0.986178</td>\n      <td>0.335748</td>\n      <td>0.360685</td>\n      <td>0.528155</td>\n      <td>2.050340</td>\n      <td>0.650057</td>\n      <td>0.268742</td>\n      <td>0.564619</td>\n      <td>1.618794</td>\n      <td>-0.226076</td>\n      <td>0.185096</td>\n      <td>2.005779</td>\n      <td>0.240895</td>\n      <td>1.482874</td>\n      <td>0.068855</td>\n      <td>2.894062</td>\n      <td>0.902985</td>\n      <td>0.179325</td>\n      <td>1.035899</td>\n      <td>-1.101531</td>\n      <td>-0.494085</td>\n      <td>-0.462855</td>\n      <td>-0.283053</td>\n      <td>-1.160801</td>\n      <td>0.214611</td>\n      <td>-0.121244</td>\n      <td>-0.272672</td>\n      <td>-0.286454</td>\n      <td>0.093911</td>\n      <td>0.003435</td>\n      <td>-0.002958</td>\n      <td>-0.155674</td>\n      <td>-0.177065</td>\n      <td>0.016265</td>\n      <td>0.051879</td>\n      <td>0.028640</td>\n      <td>0.051529</td>\n      <td>-0.451928</td>\n      <td>-0.028827</td>\n      <td>-0.388385</td>\n      <td>-0.456334</td>\n      <td>-0.188195</td>\n      <td>-0.745907</td>\n      <td>-0.197484</td>\n      <td>-0.235763</td>\n      <td>-0.624066</td>\n    </tr>\n  </tbody>\n</table>\n<p>471486 rows × 92 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Reduce Memory Method\n\nReferred to this notebook: https://www.kaggle.com/code/yuanzhezhou/jane-street-baseline-lgb-xgb-and-catboost","metadata":{}},{"cell_type":"code","source":"def reduce_mem_usage(self, float16_as32=True):\n    #memory_usage()是df每列的内存使用量,sum是对它们求和, B->KB->MB\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:#遍历每列的列名\n        col_type = df[col].dtype#列名的type\n        if col_type != object and str(col_type)!='category':#不是object也就是说这里处理的是数值类型的变量\n            c_min,c_max = df[col].min(),df[col].max() #求出这列的最大值和最小值\n            if str(col_type)[:3] == 'int':#如果是int类型的变量,不管是int8,int16,int32还是int64\n                #如果这列的取值范围是在int8的取值范围内,那就对类型进行转换 (-128 到 127)\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                #如果这列的取值范围是在int16的取值范围内,那就对类型进行转换(-32,768 到 32,767)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                #如果这列的取值范围是在int32的取值范围内,那就对类型进行转换(-2,147,483,648到2,147,483,647)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                #如果这列的取值范围是在int64的取值范围内,那就对类型进行转换(-9,223,372,036,854,775,808到9,223,372,036,854,775,807)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:#如果是浮点数类型.\n                #如果数值在float16的取值范围内,如果觉得需要更高精度可以考虑float32\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    if float16_as32:#如果数据需要更高的精度可以选择float32\n                        df[col] = df[col].astype(np.float32)\n                    else:\n                        df[col] = df[col].astype(np.float16)  \n                #如果数值在float32的取值范围内，对它进行类型转换\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                #如果数值在float64的取值范围内，对它进行类型转换\n                else:\n                    df[col] = df[col].astype(np.float64)\n    #计算一下结束后的内存\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    #相比一开始的内存减少了百分之多少\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T17:06:57.686847Z","iopub.execute_input":"2024-11-30T17:06:57.687287Z","iopub.status.idle":"2024-11-30T17:06:57.701376Z","shell.execute_reply.started":"2024-11-30T17:06:57.687251Z","shell.execute_reply":"2024-11-30T17:06:57.700035Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"reduced_data = reduce_mem_usage(final_sampled_data, False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T17:08:09.787828Z","iopub.execute_input":"2024-11-30T17:08:09.788227Z","iopub.status.idle":"2024-11-30T17:08:10.381215Z","shell.execute_reply.started":"2024-11-30T17:08:09.788192Z","shell.execute_reply":"2024-11-30T17:08:10.379812Z"}},"outputs":[{"name":"stdout","text":"Memory usage of dataframe is 162.32 MB\nMemory usage after optimization is: 84.98 MB\nDecreased by 47.6%\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Output the sampled and reduced data","metadata":{}},{"cell_type":"code","source":"reduced_data.to_csv('/kaggle/working/processed_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T17:10:19.525883Z","iopub.execute_input":"2024-11-30T17:10:19.526539Z","iopub.status.idle":"2024-11-30T17:10:59.567096Z","shell.execute_reply.started":"2024-11-30T17:10:19.526496Z","shell.execute_reply":"2024-11-30T17:10:59.565939Z"},"trusted":true},"outputs":[],"execution_count":20}]}